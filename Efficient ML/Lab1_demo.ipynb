{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP2h1MYSS2bD8//IobAJrU3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### Setup"],"metadata":{"id":"dPH95swQlO6X"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vVQFsZvmRkdi"},"outputs":[],"source":["!pip install torchprofile 1>/dev/null"]},{"cell_type":"code","source":["import copy\n","import math\n","import random\n","import time\n","from collections import OrderedDict, defaultdict\n","from typing import Union, List\n","\n","import numpy as np\n","import torch\n","from matplotlib import pyplot as plt\n","from torch import nn\n","from torch.optim import *\n","from torch.optim.lr_scheduler import *\n","from torch.utils.data import DataLoader\n","from torchprofile import profile_macs\n","from torchvision.datasets import *\n","from torchvision.transforms import *\n","from tqdm.auto import tqdm\n","\n","from torchprofile import profile_macs\n","\n","import torch.nn.functional as F\n","\n","assert torch.cuda.is_available(), \\\n","\"The current runtime does not have CUDA support.\" \\\n","\"Please go to menu bar (Runtime - Change runtime type) and select GPU\""],"metadata":{"id":"0vKNrtKcA9Q2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random.seed(0)\n","np.random.seed(0)\n","torch.manual_seed(0)"],"metadata":{"id":"aYecAgPgBGes"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(\n","    model: nn.Module,\n","    dataloader:DataLoader,\n","    criterion:nn.Module,\n","    optimizer:Optimizer,\n","    scheduler:StepLR,\n","    callbacks=None\n",") -> None:\n","  # 设置为训练模式\n","  model.train()\n","\n","  for inputs,targets in tqdm(dataloader,desc='train',leave=False):\n","    # 将数据移动到GPU\n","    inputs=inputs.cuda()\n","    targets=targets.cuda()\n","\n","    # 梯度清零\n","    optimizer.zero_grad()\n","\n","    # 前向推理\n","    outputs=model(inputs)\n","    loss=criterion(outputs,targets)\n","\n","    # 反向传播\n","    loss.backward()\n","\n","    # 更新优化器\n","    optimizer.step()\n","\n","    if callbacks is not None:\n","      for callback in callbacks:\n","        callback()\n","\n","  # 更新调度器\n","  scheduler.step()"],"metadata":{"id":"DKFsqJr9BNbD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.inference_mode()\n","def evaluate(\n","    model:nn.Module,\n","    dataloader:DataLoader,\n","    verbose=True,\n",") -> float:\n","  model.eval()\n","\n","  num_samples=0\n","  num_correct=0\n","\n","  for inputs,targets in tqdm(dataloader,desc='eval',leave=False,disable=not verbose):\n","    inputs=inputs.cuda()\n","    targets=targets.cuda()\n","\n","    outputs=model(inputs)\n","\n","    outputs=outputs.argmax(dim=-1)\n","\n","    num_samples+=targets.size(0)\n","    num_correct+=(outputs == targets).sum()\n","\n","  return (num_correct / num_samples*100).item()"],"metadata":{"id":"QPZS3nOwC2UZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Helper Functions"],"metadata":{"id":"2B0b-_2HE9kJ"}},{"cell_type":"code","source":["def get_model_macs(model,inputs) -> int:\n","  return profile_macs(model,inputs)\n","\n","def get_sparsity(tensor:torch.Tensor) -> float:\n","  return 1- float(tensor.count_nonzero()) / tensor.numel()\n","\n","def get_model_sparsity(model: nn.Module) -> float:\n","  num_nonzeros,num_elements=0,0\n","  for param in model.parameters():\n","    num_nonzeros+=param.count_nonzero()\n","    num_elements+=param.numel()\n","  return 1 - float(num_nonzeros) / num_elements\n","\n","def get_num_parameters(model: nn.Module,count_nonzero_only=False) -> int:\n","  num_counted_elements=0\n","  for param in model.parameters():\n","    if count_nonzero_only:\n","      num_counted_elements+=param.count_nonzero()\n","    else:\n","      num_counted_elements+=param.numel()\n","  return num_counted_elements\n","\n","def get_model_size(model: nn.Module,data_width=32,count_nonzero_only=False) -> int:\n","  return get_num_parameters(model,count_nonzero_only) *data_width\n","\n","Byte=8\n","KiB=1024*Byte\n","MiB=1024*KiB\n","GiB=1024*MiB"],"metadata":{"id":"ai0pbIxeE886"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Define prun functions"],"metadata":{"id":"FWBAN1jDHgF6"}},{"cell_type":"code","source":["# 逐元素判断 非结构化剪枝\n","def fine_grained_prune(tensor: torch.Tensor, sparsity: float) -> torch.Tensor:\n","  # 确保稀疏度在0-1之间\n","  sparsity=min(max(0.0,sparsity),1.0)\n","  if sparsity == 1.0:\n","    tensor.zero_()\n","    return torch.zeros_like(tensor)\n","  elif sparsity == 0.0:\n","    return torch.ones_like(tensor)\n","\n","  num_elements=tensor.numel()\n","\n","  num_zeros=round(num_elements*sparsity)\n","  importance=tensor.abs()\n","  threshold=importance.view(-1).kthvalue(num_zeros).values\n","  mask=torch.gt(importance,threshold)\n","  tensor.mul_(mask)\n","\n","  return mask"],"metadata":{"id":"r2ippWSu3JNr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FineGrainedPruner:\n","  def __init__(self,model,sparsity_dict):\n","    self.masks=FineGrainedPruner.prune(model,sparsity_dict)\n","\n","  # 禁用梯度计算\n","  @torch.no_grad()\n","  def apply(self,model):\n","    for name,param in model.named_parameters():\n","      if name in self.masks:\n","        param*=self.masks[name]\n","\n","  @staticmethod\n","  @torch.no_grad()\n","  def prune(model,sparsity_dict):\n","    masks=dict()\n","    for name,param in model.named_parameters():\n","      # 只处理多维参数（权重）\n","      if param.dim()>1:\n","        # 同意裁剪 / 分层裁剪\n","        if isinstance(sparsity_dict,dict):\n","          masks[name]=fine_grained_prune(param,sparsity_dict[name])\n","        else:\n","          assert(sparsity_dict < 1 and sparsity_dict >= 0)\n","          if sparsity_dict > 0:\n","            masks[name]=fine_grained_prune(param,sparsity_dict)\n","    return masks"],"metadata":{"id":"0MgO81Ca6WP5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load the MNIST dataset"],"metadata":{"id":"D5QtXSdjIKH7"}},{"cell_type":"code","source":["transform=transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","    ])\n","# 将标准化后的张量转换为图片\n","to_image = lambda t: (t*0.3081+0.1307).squeeze(0).to('cpu').numpy()\n","\n","dataset = {}\n","for split in [\"train\", \"test\"]:\n","  dataset[split] = MNIST(\n","    \"data\",\n","    train=(split == \"train\"),\n","    download=(split == \"train\"),\n","    transform=transform,\n","  )\n","\n","dataloader = {}\n","for split in ['train', 'test']:\n","  dataloader[split] = DataLoader(\n","    dataset[split],\n","    batch_size=256 if split == 'train' else 1000,\n","    shuffle=(split == 'train'),\n","    num_workers=0,\n","    pin_memory=True\n","  )"],"metadata":{"id":"NjN4zbGmIJt6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["demos = {0: 3, 1: 2, 2: 1, 3: 30, 4: 4, 5: 15, 6: 11, 7: 0, 8: 61, 9: 9}\n","demo_inputs, demo_images = [], []\n","# 对比模型预测输出和对应标签\n","for digit, index in demos.items():\n","    demo_inputs.append(copy.deepcopy(dataset['test'][index][0]))\n","    demo_images.append(to_image(demo_inputs[-1]))\n","demo_inputs = torch.stack(demo_inputs).cuda()"],"metadata":{"id":"5oEFecDfJfub"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Neural Network Model"],"metadata":{"id":"l3qSnbijKKwS"}},{"cell_type":"code","source":["class Net(nn.Module):\n","  def __init__(self):\n","    super(Net,self).__init__()\n","    self.conv1=nn.Conv2d(1,32,3,1)\n","    self.conv2=nn.Conv2d(32,64,3,1)\n","    self.dropout1=nn.Dropout(0.25)\n","    self.dropout2=nn.Dropout(0.5)\n","    self.fc1=nn.Linear(9216,128)\n","    self.fc2=nn.Linear(128,10)\n","\n","  def forward(self,x):\n","    x = self.conv1(x)\n","    x = F.relu(x)\n","    x = self.conv2(x)\n","    x = F.relu(x)\n","    x = F.max_pool2d(x, 2)\n","    x = self.dropout1(x)\n","    x = torch.flatten(x, 1)\n","    x = self.fc1(x)\n","    x = F.relu(x)\n","    x = self.dropout2(x)\n","    x = self.fc2(x)\n","    output = F.log_softmax(x, dim=1)\n","    return output\n","model=Net().cuda()"],"metadata":{"id":"8eUCydsMKRDv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Visualize the Demo Images"],"metadata":{"id":"D6pYwNcHN_fE"}},{"cell_type":"code","source":["def visualize(with_predictions=False):\n","    plt.figure(figsize=(20, 10))\n","    predictions = model(demo_inputs).argmax(dim=1) if with_predictions else None\n","    for digit, index in demos.items():\n","        plt.subplot(1, 10, digit + 1)\n","        plt.imshow(demo_images[digit])\n","        if predictions is None:\n","            plt.title(f\"digit: {digit}\")\n","        else:\n","            plt.title(f\"digit: {digit}\\npred: {int(predictions[digit])}\")\n","        plt.axis('off')\n","    plt.show()\n","\n","visualize()"],"metadata":{"id":"DCgw327BN6Sy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Pre-train Neural Network on MNIST"],"metadata":{"id":"qqRM9W7GOIlk"}},{"cell_type":"code","source":["lr = 1.0\n","lr_step_gamma = 0.7\n","num_epochs = 5\n","\n","optimizer = Adadelta(model.parameters(), lr=lr)\n","criterion = F.nll_loss\n","scheduler = StepLR(optimizer, step_size=1, gamma=lr_step_gamma)\n","\n","best_accuracy = 0\n","best_checkpoint = dict()\n","for epoch in range(num_epochs):\n","    train(model, dataloader['train'], criterion, optimizer, scheduler)\n","    accuracy = evaluate(model, dataloader['test'])\n","    is_best = accuracy > best_accuracy\n","    if is_best:\n","        best_checkpoint['state_dict'] = copy.deepcopy(model.state_dict())\n","        best_accuracy = accuracy\n","    print(f'    Epoch {epoch+1:>2d} Accuracy {accuracy:.2f}% / Best Accuracy: {best_accuracy:.2f}%')\n","\n","print(f\"=> loading best checkpoint\")\n","model.load_state_dict(best_checkpoint['state_dict'])\n","recover_model = lambda: model.load_state_dict(best_checkpoint['state_dict'])"],"metadata":{"id":"kJTQJFO2OHme"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dense_model_accuracy = evaluate(model, dataloader['test'])\n","dense_model_size = get_model_size(model)\n","print(f\"dense model has accuracy={dense_model_accuracy:.2f}%\")\n","print(f\"dense model has size={dense_model_size/MiB:.2f} MiB\")\n","visualize(True)"],"metadata":{"id":"a7aah_YtOELH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sparsity = 0.99\n","# 加载最佳权重\n","recover_model()\n","pruner = FineGrainedPruner(model, sparsity)\n","pruner.apply(model)\n","sparse_model_accuracy = evaluate(model, dataloader['test'])\n","sparse_model_size = get_model_size(model, count_nonzero_only=True)\n","print(f\"{sparsity*100}% sparse model has accuracy={sparse_model_accuracy:.2f}%\")\n","print(f\"{sparsity*100}% sparse model has size={sparse_model_size/MiB:.2f} MiB, \"\n","      f\"which is {dense_model_size/sparse_model_size:.2f}X smaller than \"\n","      f\"the {dense_model_size/MiB:.2f} MiB dense model\")\n","visualize(True)"],"metadata":{"id":"HRKY7qhZQJVL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_finetune_epochs = 2\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_finetune_epochs)\n","\n","best_sparse_checkpoint = dict()\n","best_sparse_accuracy = 0\n","print(f'微调剪枝后的模型')\n","for epoch in range(num_finetune_epochs):\n","\n","    train(model, dataloader['train'], criterion, optimizer, scheduler,\n","          callbacks=[lambda: pruner.apply(model)])\n","    accuracy = evaluate(model, dataloader['test'])\n","    is_best = accuracy > best_sparse_accuracy\n","    if is_best:\n","        best_sparse_checkpoint['state_dict'] = copy.deepcopy(model.state_dict())\n","        best_sparse_accuracy = accuracy\n","    print(f'    Epoch {epoch+1} Sparse Accuracy {accuracy:.2f}% / Best Sparse Accuracy: {best_sparse_accuracy:.2f}%')\n","\n"],"metadata":{"id":"RchEY9HkQQ3Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(best_sparse_checkpoint['state_dict'])\n","sparse_model_accuracy = evaluate(model, dataloader['test'])\n","sparse_model_size = get_model_size(model, count_nonzero_only=True)\n","print(f\"{sparsity*100}% sparse model has accuracy={sparse_model_accuracy:.2f}%\")\n","print(f\"{sparsity*100}% sparse model has size={sparse_model_size/MiB:.2f} MiB, \"\n","      f\"which is {dense_model_size/sparse_model_size:.2f}X smaller than \"\n","      f\"the {dense_model_size/MiB:.2f} MiB dense model\")\n","visualize(True)"],"metadata":{"id":"bzkFRVOCRf9d"},"execution_count":null,"outputs":[]}]}